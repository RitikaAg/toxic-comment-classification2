{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"# This is a script version of Meng Ye's Notebook: https://www.kaggle.com/konohayui/bi-gru-cnn-poolings/code\n# I'm trying to reproduce the best single public script model in a GPU kernel.\n\nimport time\nstart_time = time.time()\nfrom sklearn.model_selection import train_test_split\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd\nnp.random.seed(32)\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.engine import InputSpec, Layer\n\nimport logging\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\n\nclass RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n            \n            \ntrain = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\ntest = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/test.csv\")\nembedding_path = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\"\n#embedding_path = \"../input/glove840b300dtxt/glove.840B.300d.txt\"\nembed_size = 300\nmax_features = 130000\nmax_len = 220\n\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\ntrain[\"comment_text\"].fillna(\"no comment\")\ntest[\"comment_text\"].fillna(\"no comment\")\nX_train, X_valid, Y_train, Y_valid = train_test_split(train, y, test_size = 0.1)\n\nraw_text_train = X_train[\"comment_text\"].str.lower()\nraw_text_valid = X_valid[\"comment_text\"].str.lower()\nraw_text_test = test[\"comment_text\"].str.lower()\n\ntk = Tokenizer(num_words = max_features, lower = True)\ntk.fit_on_texts(raw_text_train)\nX_train[\"comment_seq\"] = tk.texts_to_sequences(raw_text_train)\nX_valid[\"comment_seq\"] = tk.texts_to_sequences(raw_text_valid)\ntest[\"comment_seq\"] = tk.texts_to_sequences(raw_text_test)\n\nX_train = pad_sequences(X_train.comment_seq, maxlen = max_len)\nX_valid = pad_sequences(X_valid.comment_seq, maxlen = max_len)\ntest = pad_sequences(test.comment_seq, maxlen = max_len)\n\ndef get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n\nword_index = tk.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.zeros((nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n    \n    \nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n\nfile_path = \"best_model.hdf5\"\ncheck_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n                              save_best_only = True, mode = \"min\")\nra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\nearly_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n\ndef build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n    inp = Input(shape = (max_len,))\n    x = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n    x1 = SpatialDropout1D(dr)(x)\n\n    x = Bidirectional(GRU(units, return_sequences = True))(x1)\n    x = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n    \n    y = Bidirectional(LSTM(units, return_sequences = True))(x1)\n    y = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(y)\n    \n    avg_pool1 = GlobalAveragePooling1D()(x)\n    max_pool1 = GlobalMaxPooling1D()(x)\n    \n    avg_pool2 = GlobalAveragePooling1D()(y)\n    max_pool2 = GlobalMaxPooling1D()(y)\n    \n    \n    x = concatenate([avg_pool1, max_pool1, avg_pool2, max_pool2])\n\n    x = Dense(6, activation = \"sigmoid\")(x)\n    model = Model(inputs = inp, outputs = x)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    history = model.fit(X_train, Y_train, batch_size = 128, epochs = 3, validation_data = (X_valid, Y_valid), \n                        verbose = 1, callbacks = [ra_val, check_point, early_stop])\n    model = load_model(file_path)\n    return model\n    \n    \nmodel = build_model(lr = 1e-3, lr_d = 0, units = 112, dr = 0.2)\npred = model.predict(test, batch_size = 1024, verbose = 1)\n\nsubmission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\nsubmission[list_classes] = (pred)\nsubmission.to_csv(\"submission.csv\", index = False)\nprint(\"[{}] Completed!\".format(time.time() - start_time))","execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}